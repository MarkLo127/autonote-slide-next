# === 1) è‡ªå‹•å°‹æ‰¾å« backend/ çš„å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼ŒåŠ å…¥ sys.path ===
import sys
from pathlib import Path

_here = Path(__file__).resolve()
for parent in [_here.parent, *_here.parents]:
    if (parent / "backend").exists():
        if str(parent) not in sys.path:
            sys.path.insert(0, str(parent))
        break
# === end of sys.path patch ===

# === 2) ä½ çš„åŸæœ¬åŒ¯å…¥ï¼ˆä¿æŒä¸è®Šï¼‰===
import asyncio
import json
import os
import uuid
from datetime import datetime, timezone
from pathlib import Path as _Path
from typing import Any, Dict, List

import streamlit as st
import streamlit.components.v1 as components
from PIL import Image, UnidentifiedImageError

# === å°ˆæ¡ˆå¼•ç”¨ï¼ˆä¿æŒä½ åŸæœ¬çš„åŒ¯å…¥ï¼‰===
from backend.app.core.config import UPLOAD_DIR
from backend.app.models.schemas import LLMSettings
from backend.app.services.nlp.keyword_extractor import extract_keywords_by_paragraph
from backend.app.services.nlp.language_detect import detect_lang
from backend.app.services.nlp.segmenter import ensure_offsets_if_needed
from backend.app.services.nlp.summarizer import (
    summarize_by_paragraph,
    summarize_global,
)
from backend.app.services.parsing.file_loader import load_file_as_text_and_paragraphs
from backend.app.services.mindmap.mindmap_gen import (
    build_graphviz_mindmap,
    build_mermaid_mindmap,
    infer_doc_title,
    save_graphviz_png,
    select_root_label,
    save_mermaid,
)
from backend.app.services.storage import make_public_url
from backend.app.services.wordcloud.wordcloud_gen import build_wordcloud


class process:
    # === ç‹€æ…‹åˆå§‹åŒ–ï¼šåœ¨ session_state å»ºç«‹åˆ†æçµæœå®¹å™¨ ===
    @staticmethod
    def _ensure_state():
        if "analysis_results" not in st.session_state:
            st.session_state["analysis_results"] = {}

    # === åŒæ­¥åŸ·è¡Œ async å”ç¨‹ï¼ˆåœ¨ Streamlit ä¸‹å®‰å…¨åŸ·è¡Œï¼‰===
    @staticmethod
    def _run_sync(coro):
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            return asyncio.run(coro)
        else:
            return loop.run_until_complete(coro)

    # === å°‡ Streamlit ä¸Šå‚³ç‰©ä»¶å¯«å…¥ UPLOAD_DIRï¼Œä¸¦å›å‚³æª”æ¡ˆè·¯å¾‘ ===
    @staticmethod
    def _save_streamlit_upload(uploaded_file) -> str:
        os.makedirs(UPLOAD_DIR, exist_ok=True)
        suffix = _Path(uploaded_file.name).suffix or ""
        filename = f"up_{datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S%f')}{suffix}"
        output_path = _Path(UPLOAD_DIR) / filename
        output_path.write_bytes(uploaded_file.getbuffer())
        return str(output_path)

    # === å°‡æ®µè½ç‰©ä»¶å®‰å…¨è½‰ç‚º dictï¼ˆå…¼å®¹ pydantic / ä¸€èˆ¬ç‰©ä»¶ï¼‰===
    @staticmethod
    def _paragraph_to_dict(paragraph) -> Dict[str, Any]:
        if hasattr(paragraph, "model_dump"):
            data = paragraph.model_dump()
        else:
            data = {
                "index": getattr(paragraph, "index", 0),
                "text": getattr(paragraph, "text", ""),
                "start_char": getattr(paragraph, "start_char", 0),
                "end_char": getattr(paragraph, "end_char", 0),
            }
        data.setdefault("text", "")
        return data

    @staticmethod
    def _render_doc_header(res: Dict[str, Any]):
        title = (res.get("doc_title") or res.get("file_name") or "æœªå‘½å").strip()
        st.markdown(f"### ğŸ“„ {title}")
        original = res.get("file_name")
        if original and original != title:
            st.caption(f"åŸå§‹æª”åï¼š{original}")

    @staticmethod
    def _render_mermaid_diagram(mermaid_code: str):
        if not mermaid_code:
            return
        element_id = f"mindmap_{uuid.uuid4().hex}"
        graph_json = json.dumps(mermaid_code)
        components.html(
            f"""
            <div id="{element_id}" style="width: 100%;"></div>
            <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
            <script>
              const graphDefinition = {graph_json};
              const mount = document.getElementById("{element_id}");
              const renderMindmap = () => {{
                if (!window.mermaid) {{
                  setTimeout(renderMindmap, 60);
                  return;
                }}
                try {{
                  mermaid.initialize({{ startOnLoad: false }});
                  mermaid.render("{element_id}_svg", graphDefinition, (svgCode) => {{
                    mount.innerHTML = svgCode;
                  }});
                }} catch (err) {{
                  console.error('Mermaid render error', err);
                }}
              }};
              renderMindmap();
            </script>
            """,
            height=600,
            scrolling=True,
        )

    # === æ ¸å¿ƒï¼šåˆ†ææ–‡ä»¶ï¼ˆå…¨å±€æ‘˜è¦ã€æ®µè½æ‘˜è¦ã€é—œéµå­—ã€æ–‡å­—é›²è·¯å¾‘ï¼‰===
    @staticmethod
    def analyze_document(uploaded_file, settings: LLMSettings) -> Dict[str, Any]:
        result: Dict[str, Any] = {"file_name": uploaded_file.name}

        # 1) è®€æª”èˆ‡æ–‡å­—è§£æ
        try:
            saved_path = process._save_streamlit_upload(uploaded_file)
            full_text, paragraphs = load_file_as_text_and_paragraphs(saved_path)
        except ValueError as exc:
            result["error"] = str(exc)
            return result
        except Exception as exc:  # pylint: disable=broad-except
            result["error"] = f"ä¸Šå‚³æª”æ¡ˆè™•ç†å¤±æ•—ï¼š{exc}"
            return result

        if not full_text.strip():
            result["error"] = "è§£æä¸åˆ°æ–‡å­—å…§å®¹ï¼Œå¯èƒ½æ˜¯æƒæå½±åƒæˆ–å—ä¿è­·æ–‡ä»¶ã€‚"
            return result

        # 2) èªè¨€åµæ¸¬èˆ‡æ®µè½åç§»è£œå…¨
        lang = detect_lang(full_text)
        paragraphs = ensure_offsets_if_needed(full_text, paragraphs)
        doc_title = infer_doc_title(paragraphs, uploaded_file.name)
        paragraph_dicts = [process._paragraph_to_dict(p) for p in paragraphs]

        # 3) LLM æ‘˜è¦ï¼ˆå…¨å±€ + æ®µè½ï¼‰
        try:
            global_summary = process._run_sync(summarize_global(full_text, settings))
            paragraph_summaries = process._run_sync(
                summarize_by_paragraph(paragraphs, settings)
            )
        except Exception as exc:  # pylint: disable=broad-except
            result["error"] = f"LLM å‘¼å«å¤±æ•—ï¼š{exc}"
            return result

        paragraph_summaries = [
            {"paragraph_index": item["paragraph_index"], "summary": item["summary"]}
            for item in paragraph_summaries
        ]

        # 4) é—œéµå­—ï¼ˆé€æ®µï¼‰
        paragraph_keywords = extract_keywords_by_paragraph(paragraphs, lang)
        paragraph_keywords = [
            {
                "paragraph_index": item["paragraph_index"],
                "keywords": item.get("keywords", []),
            }
            for item in paragraph_keywords
        ]

        # 5) ä¸»è¦æ¨™é¡Œå–é—œéµå­—ï¼ˆè‹¥ç„¡å‰‡æ²¿ç”¨ï¼‰
        doc_title = select_root_label(paragraph_keywords, doc_title)
        result["doc_title"] = doc_title

        # 6) æ–‡å­—é›²ï¼ˆè‹¥å¤±æ•—å‰‡è¨˜éŒ„éŒ¯èª¤è¨Šæ¯ï¼‰
        wordcloud_path = None
        wordcloud_error = None
        try:
            wordcloud_path = build_wordcloud(paragraph_keywords, lang)
        except RuntimeError as exc:
            wordcloud_error = str(exc)

        # 7) å¿ƒæ™ºåœ–ï¼ˆMermaid + åœ–ç‰‡ + ä¸‹è¼‰é€£çµï¼‰
        mindmap_mermaid = ""
        mindmap_file_url: str | None = None
        mindmap_error: str | None = None
        mindmap_image_path: str | None = None
        mindmap_image_url: str | None = None
        try:
            mindmap_mermaid = build_mermaid_mindmap(doc_title, paragraph_keywords)
            mindmap_abs, _ = save_mermaid(mindmap_mermaid, name_hint=doc_title)
            mindmap_file_url = make_public_url(mindmap_abs)

            graph = build_graphviz_mindmap(doc_title, paragraph_keywords)
            png_path, _ = save_graphviz_png(graph, name_hint=doc_title)
            if png_path:
                mindmap_image_path = png_path
                mindmap_image_url = make_public_url(png_path)
        except Exception as exc:  # pylint: disable=broad-except
            mindmap_error = f"å¿ƒæ™ºåœ–ç”Ÿæˆå¤±æ•—ï¼š{exc}"

        # 8) çµ„è£çµæœ
        result.update(
            {
                "language": lang,
                "paragraphs": paragraph_dicts,
                "global_summary": global_summary,
                "paragraph_summaries": paragraph_summaries,
                "paragraph_keywords": paragraph_keywords,
                "wordcloud_path": wordcloud_path,
                "wordcloud_error": wordcloud_error,
                "doc_title": doc_title,
                "mindmap_mermaid": mindmap_mermaid,
                "mindmap_file_url": mindmap_file_url,
                "mindmap_image_path": mindmap_image_path,
                "mindmap_image_url": mindmap_image_url,
                "mindmap_error": mindmap_error,
            }
        )
        return result

    # === é¡¯ç¤ºï¼šæ–‡å­—é›²ï¼ˆåƒ…æ–¼é—œéµå­—é é¡¯ç¤ºï¼‰===
    @staticmethod
    def render_wordcloud(path: str, error: str | None):
        if path:
            try:
                with Image.open(path) as img:
                    st.image(img, caption="æ–‡å­—é›²", use_container_width=True)
            except (FileNotFoundError, UnidentifiedImageError):
                st.warning("æ–‡å­—é›²åœ–ç‰‡è®€å–å¤±æ•—ï¼Œè«‹é‡æ–°ç”Ÿæˆã€‚")
        elif error:
            st.warning(error)

    # === é¡¯ç¤ºé ï¼šæ‘˜è¦æ•´ç†ï¼ˆåªé¡¯ç¤ºæ‘˜è¦ï¼Œä¸é¡¯ç¤ºé—œéµå­—/æ–‡å­—é›²/å¿ƒæ™ºåœ–ï¼‰===
    @staticmethod
    def render_summary_view(results: List[Dict[str, Any]]):
        if not results:
            st.info("å°šæœªç”¢ç”Ÿæ‘˜è¦ï¼Œè«‹å…ˆä¸Šå‚³æ–‡ä»¶ä¸¦é»æ“Šã€Œé–‹å§‹æ‘˜è¦æ•´ç†ã€ã€‚")
            return

        for res in results:
            st.divider()
            process._render_doc_header(res)
            if res.get("error"):
                st.error(res["error"])
                continue

            st.caption(f"èªè¨€åµæ¸¬ï¼š{res['language']}")
            st.markdown("**å…¨å±€æ‘˜è¦**")
            st.write(res["global_summary"])

            with st.expander("æ®µè½æ‘˜è¦", expanded=False):
                for item in res["paragraph_summaries"]:
                    idx = item["paragraph_index"] + 1
                    st.markdown(f"**ç¬¬ {idx} æ®µ**")
                    st.write(item["summary"])

    # === é¡¯ç¤ºé ï¼šé—œéµå­—æ“·å–ï¼ˆåªé¡¯ç¤ºé—œéµå­—è¡¨èˆ‡æ–‡å­—é›²ï¼‰===
    @staticmethod
    def render_keywords_view(results: List[Dict[str, Any]]):
        if not results:
            st.info("å°šæœªæ“·å–é—œéµå­—ï¼Œè«‹å…ˆä¸Šå‚³æ–‡ä»¶ä¸¦é»æ“Šã€Œé–‹å§‹é—œéµå­—æ“·å–ã€ã€‚")
            return

        for res in results:
            st.divider()
            process._render_doc_header(res)
            if res.get("error"):
                st.error(res["error"])
                continue

            table_rows = [
                {
                    "æ®µè½": item["paragraph_index"] + 1,
                    "é—œéµå­—": "ã€".join(item.get("keywords", [])) or "ç„¡",
                }
                for item in res["paragraph_keywords"]
            ]
            st.dataframe(table_rows, use_container_width=True)
            process.render_wordcloud(res.get("wordcloud_path") or "", res.get("wordcloud_error"))

    # === é¡¯ç¤ºé ï¼šå¿ƒæ™ºåœ–ç”Ÿæˆï¼ˆé¡¯ç¤º Mermaid mindmap èˆ‡ä¸‹è¼‰é€£çµï¼‰===
    @staticmethod
    def render_mindmap_view(results: List[Dict[str, Any]]):
        if not results:
            st.info("å°šæœªç”Ÿæˆå¿ƒæ™ºåœ–ï¼Œè«‹å…ˆä¸Šå‚³æ–‡ä»¶ä¸¦é»æ“Šã€Œé–‹å§‹ç”Ÿæˆå¿ƒæ™ºåœ–ã€ã€‚")
            return

        for res in results:
            st.divider()
            process._render_doc_header(res)
            if res.get("error"):
                st.error(res["error"])
                continue

            mermaid = (res.get("mindmap_mermaid") or "").strip()
            download_url = res.get("mindmap_file_url") or ""
            mindmap_error = res.get("mindmap_error")
            image_path = res.get("mindmap_image_path") or ""
            image_url = res.get("mindmap_image_url") or ""
            if mindmap_error:
                st.warning(mindmap_error)

            if image_path and os.path.exists(image_path):
                st.image(image_path, caption="å¿ƒæ™ºåœ–", use_container_width=True)
            elif image_url:
                st.image(image_url, caption="å¿ƒæ™ºåœ–", use_container_width=True)
            elif mermaid:
                process._render_mermaid_diagram(mermaid)
            elif not mindmap_error:
                st.info("å°šç„¡å¿ƒæ™ºåœ–å…§å®¹ï¼Œè«‹ç¢ºèªé—œéµå­—æ˜¯å¦ç”¢ç”ŸæˆåŠŸã€‚")
